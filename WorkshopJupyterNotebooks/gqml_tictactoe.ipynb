{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric-QML : Tic-Tac-Toe\n",
    "\n",
    "This notebook shows an implementation of the Tic-Tac-Toe game using G-QML. \n",
    "\n",
    "First, import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import EfficientSU2\n",
    "from qiskit.algorithms.optimizers import ADAM\n",
    "\n",
    "import gqml_helpers as helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Load **tic-tac-toe.csv**. \n",
    "\n",
    "Reference : Aha,David. (1991). Tic-Tac-Toe Endgame. UCI Machine Learning Repository. https://doi.org/10.24432/C5688J."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tic-tac-toe_csv.csv', newline = '') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data\n",
    "\n",
    "Flatten board positions into numerical vectors \n",
    "\n",
    "x present -> 1\n",
    "\n",
    "empty square -> 0\n",
    "\n",
    "o present -> -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {'x': 1, 'b': 0, 'o': -1}\n",
    "positions = np.zeros([len(data[1:]),9])\n",
    "for i in range(1,len(data)):\n",
    "    for j in range(9):\n",
    "        positions[i-1,j] = encoding[data[i][j]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying labels\n",
    "The original dataset contains two classes: X won or X did not win.\n",
    "\n",
    "We separate the data into three classes: win for X ([1, -1, -1]), draw ([-1, 1, -1]), or win for O ([-1, -1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(positions)):\n",
    "    labels.append(np.array(helpers.who_won(positions[i])))\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos, train_labels, test_pos, test_labels = helpers.split_data(0.2, positions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Parameters dictionary for later use in quantum circuit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_param_dict = {}\n",
    "for i in range(9):\n",
    "    data_param_dict[f'x_{i}'] = Parameter(f'x_{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function\n",
    "\n",
    "The loss function runs over all elements in the training set and calculates the L2 norm between the prediction and target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(qc, train_pos, train_classes, theta_list):\n",
    "    loss_val = 0\n",
    "    for i, pos in enumerate(train_pos):\n",
    "        to_bind = np.concatenate((theta_list, pos), axis=0)\n",
    "        qc_temp = qc.bind_parameters(to_bind)\n",
    "        label = np.array([helpers.measure_z_corners(qc_temp), helpers.measure_z_mid(qc_temp), helpers.measure_z_edges(qc_temp)])\n",
    "        loss_val += np.linalg.norm(label - train_classes[i])**2\n",
    "    return loss_val/len(train_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Quantum circuit\n",
    "\n",
    "Create a quantum circuit as described in https://journals.aps.org/prxquantum/pdf/10.1103/PRXQuantum.4.010328."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 2\n",
    "blocks = 2\n",
    "qc_equivariant = helpers.make_full_circuit(layers, blocks, data_param_dict)\n",
    "qc_equivariant.decompose().draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Optimizer \n",
    "\n",
    "We use the Qiskit implementation of the ADAM optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(maxiter=50,\n",
    "               tol=1e-6,\n",
    "               lr=0.1,\n",
    "               beta_1=0.9,\n",
    "               beta_2=0.99,\n",
    "               noise_factor=1e-8,\n",
    "               eps=1e-10,\n",
    "               amsgrad=False,\n",
    "               snapshot_dir=None)\n",
    "\n",
    "start = 0.5 * np.pi * (np.random.rand(36) - 0.5)\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run minimization process\n",
    "Warning: this takes a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = opt.minimize(lambda x: loss(qc_equivariant, train_pos, train_labels, x), x0 = start, bounds = [-np.pi, np.pi])\n",
    "print(helpers.score(qc_equivariant, res.x, test_pos, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with pre-obtained parameters\n",
    "\n",
    "As the optimization loop is quite long to run, the following parameters are given. These are the result of one optimization process. They give around 72% accuracy on test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_params = [ 0.85088804, -0.16598115,  0.26359942,  0.562003  , -0.04098523,\n",
    "                  0.62178465, -0.71733895,  0.04031313,  0.92661584,  0.21138858,\n",
    "                 -0.65799891,  0.85270021,  0.50494867,  0.74347194, -0.66101966,\n",
    "                  0.20141943,  0.29542234,  0.04507088, -0.45123592, -0.09142401,\n",
    "                  0.96749934, -0.37687953, -0.11190734, -0.99035946,  0.58611021,\n",
    "                 -0.49306862,  0.0736983 ,  0.31039856,  1.62303328, -0.02937282,\n",
    "                  0.35112483, -1.82985848, -0.05467669,  1.06182326, -0.45204521,\n",
    "                  0.18327106]\n",
    "\n",
    "print(helpers.score(qc_equivariant, sample_params, test_pos, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a non-geometric QML model\n",
    "\n",
    "For comparison purpose, define a non-geometric QML model. This model is agnostic to any symmetry. It has 36 parameters, just like the G-QML model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_agnostic_circuit(data_param_dict):\n",
    "    qc = QuantumCircuit(9)\n",
    "    for j in range(9):\n",
    "        qc.rx(2 * np.pi / 3 * data_param_dict[f'x_{j}'], j)\n",
    "    qc.append(EfficientSU2(num_qubits = 9, reps = 1, parameter_prefix = 'theta'), range(9))\n",
    "    return qc\n",
    "\n",
    "qc_agnostic = define_agnostic_circuit(data_param_dict)\n",
    "qc_agnostic.decompose().decompose().draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run minimization process\n",
    "Warning: this also takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_agn = opt.minimize(lambda x: loss(qc_agnostic, train_pos, train_labels, x), x0 = start, bounds = [-np.pi, np.pi])\n",
    "print(helpers.score(qc_agnostic, res_agn.x, test_pos, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with sample parameters\n",
    "\n",
    "This is what I obtained as a result of 1 optimization. The accuracy is around 45% on test data, significantly worse than the geometric model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_params_agn = [ 2.60820587, -2.36543919,  0.00241482,  0.70965185, -1.2097236 ,\n",
    "        1.46766323, -1.00959514, -1.11436405, -1.20381658, -1.40004612,\n",
    "        1.47004275, -1.50029131, -0.82709146,  0.41857608, -1.84802844,\n",
    "       -1.37763997, -1.23584003, -1.23057168,  1.72378491, -2.31549326,\n",
    "        1.66816684,  0.66558259,  1.15545305,  1.56933712,  1.78319254,\n",
    "       -2.34117593,  2.07923172,  0.52225609, -0.39391978, -0.05000988,\n",
    "       -0.7884391 , -0.28555215,  0.18436415, -1.25122078,  0.20366388,\n",
    "        0.17484095]\n",
    "\n",
    "print(helpers.score(qc_agnostic, sample_params_agn, test_pos, test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
